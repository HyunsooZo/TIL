# 👯‍♂️ Performance : Cache Stampede

## Cache Stampede?

캐시 스캠피드() 현상은 다수의 요청이 동시에 캐시에 접근했을 때, \
해당 키에 대한 데이터가 캐시에 존재하지 않아 모든 요청이 동시에 **백엔드(주로 DB)** 를 향해 몰리는 상황을 말한다. \
이로 인해 **중복된 읽기 및 쓰기 작업**이 발생하며, 시스템의 부하가 급격히 증가할 수 있다.

***

## Why is it a problem?

다음은 캐시 스캠피드가 발생하는 대표적인 시나리오이다:

* 다수의 스레드가 동시에 동일한 키를 조회한다.
* 해당 키가 캐시에 존재하지 않아 모두 **캐시 미스**가 발생한다.
* 모든 요청이 동시에 DB에 접근하여 **중복 읽기**가 발생한다.
* 각 요청이 읽은 데이터를 다시 캐시에 저장하려 하여 **중복 쓰기**가 발생한다.
* 그 결과, 백엔드(DB)의 부하가 급증하거나 장애가 발생할 수 있다.

***

## Visualization

<figure><img src="../../.gitbook/assets/스크린샷 2025-05-17 22.52.44.png" alt=""><figcaption></figcaption></figure>

* 파란색 박스: **동시에 발생한 캐시 미스**
* 분홍색 박스: **동시에 발생한 DB 조회 (중복 읽기)**
* 초록색 박스: **동시에 발생한 캐시 저장 (중복 쓰기)**

***

## How to prevent it?

캐시 스캠피드를 방지하기 위해 다음과 같은 방법들이 사용된다:

### **Locking (Mutex)**

* 캐시 조회 직후, 해당 키에 대한 락을 설정하고, 락을 잡은 스레드만 백엔드에서 데이터를 읽고 캐시에 저장하도록 한다.
* 락을 잡지 못한 스레드는 대기하거나 이전 값을 응답받는다.

```java
if (!cache.contains(key)) {
    synchronized (key.intern()) {
        if (!cache.contains(key)) {
            var data = db.read(key);
            cache.put(key, data);
        }
    }
}
```

### **Early Refresh**

* 캐시가 만료되기 전에 백그라운드 작업으로 미리 데이터를 갱신해놓는다.
* 사용자는 항상 유효한 캐시를 조회하게 되어 스탬피드를 피할 수 있다.

### **Randomized TTL (Time-To-Live)**

* 동일한 시간에 캐시가 만료되지 않도록, TTL을 무작위로 분산시킨다.

```java
// TTL: 5분 ± 30초
var ttl = 5 * 60 + random.nextInt(60)
```

### **Request Coalescing**&#x20;

* 동일한 키에 대한 중복 요청을 하나로 묶어서 처리한다.

***

## Summary

* 캐시 스캠피드는 다수의 요청이 동시에 캐시 미스를 일으켜 백엔드에 부담을 주는 현상이다.
* 락, 랜덤 TTL, 선제적 갱신 등 다양한 전략으로 예방할 수 있다.
* 고부하 시스템이나 트래픽이 많은 서비스에서는 반드시 대응이 필요하다.
* 아직 겪어보지 못했고, 트래픽이 아주 많은 서비스 개발을 하고 있지는 않아서 일단 알아두면 좋을 것 같다.
